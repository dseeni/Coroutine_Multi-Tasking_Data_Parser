# Python Deep Dive Part 2 Project 6

### Cooperative Multitasking Using Coroutines:

- Coroutine based Data Processing Pipeline:
    - [x] Concurrent Data Flow processing  at every stage of the pipeline...

    - [x] handle any number of files, of any length, for any number of filters

    - [x] multitask across all input files, broadcasting every row concurrently

    - [x] evaluate each row against any number of defined filters per input file
    
    - [x] dynamically infer data types and parse data concurrently

    - [x] robust error handling accounts for potential unclean data samples

    - [x] handle multiple date formats from a user defined format library

    - [x] generate user defined named tuples for each row processed
    
    - [x] write out multiple result files into custom directory / file names



