-------------------------------------------------------------------------------
SAMPLE DATA: "Chevrolet Chevelle Malibu;18.0;8;307.0;130.0;3504.;12.0;70;US"
-------------------------------------------------------------------------------
User Provides:
a files nested dictionary:
        {filename_1: {outputfile_1: lambda filter
                     outputfile_2: lambda filter
                     outputfile_3: lambda filter}

        filename_1: {outputfile_1: lambda filter
                     outputfile_2: lambda filter
                     outputfile_3: lambda filter}}
--------------------------------------------------------------------------------
# TODO: Checklist
--------------------------------------------------------------------------------
# TODO: make your test objects send to targets based on
# TODO: arguments, easy to test then

# TODO: overwrite file
# TODO: if file exists delete
# TODO: concatenate file name
# TODO: join os path
# TODO: read and overwrite a file in Python

# TODO: pytest capturing of the stdout/stderr output
# TODO: pytest temp directory and testing csv
--------------------------------------------------------------------------------
user_input:
# todo: create a funciton that orgaizes the files as ordereddict/subdict maybe?
format:
a dictionary of filters:
    {tuple(file_name_1, data row name): 'function_name': lambda_func
    tuple(file_name_2, data row name): 'function_name': lambda_func
    tuple(file_name_3, data row name): 'function_name': lambda_func}

    output_file = str(file_name - "input_data") + str(function_name)

    pipeline_handler --> opens all the files and closes them:
    (the only context manager in the program)
        for file in files_dictionary:
        with file open:
            -read the row --> send the row for header extraction
                         \--> send the row for data type key generation


        -extract headers --> create named tuple named tuple send next(line) to
        infer

        -infer data type--> sample the line and return a string

        -sample data row(take in parse key)
            sample data row call next  #now at data lines


    data_reader --> cast

    headers extract gets sent user defined headers, and sends those to filters

    filter_predicates --> recieves tracking headers yield 1

    filters -->
                recieves named tuple yield 2
                if all namedtuple values exist in named tuple from tracking
                fileds send to save data else consume it

    broadcaster -->
    broadcaster = broadcast(filters) # filters = targets
    
    def pred_ford_green(data_row):
        return (data_row[idx_make].lower() == 'ford'
                and data_row[idx_color].lower() == 'green')

    filter_ford_green = filter_data(pred_ford_green, out_ford_green)

    filter_older = filter_data(lambda d: d[idx_year] <= 2010, out_older)
        filter_pink_cars = filter_data
        (lambda d: d[idx_color].lower() == 'pink', out_pink_cars)

        filter_ford_green = filter_data(pred_ford_green, out_ford_green)

        filter_older = filter_data(lambda d: d[idx_year] <= 2010, out_older)

        filters = (filter_pink_cars, filter_ford_green, filter_older)
        broadcaster = broadcast(filters)

# track fields --> Deepak's filter tracker
def filterpredicate(tuple: track_fileds):
    for track_field in track_fields:
        if all(namedtuple.track_field for trackfield in trackfields):
            return named.tuple


    while True:
        data_row = yield
        broadcaster.send(data_row)


-------------------------------------------------------------------------------
@coroutine
def pipeline_coro():
    out_pink_cars = save_data('pink_cars.csv', headers)
    out_ford_green = save_data('ford_green.csv', headers)
    out_older = save_data('older.csv', headers)

    filter_pink_cars = filter_data(lambda d: d[idx_color].lower() == 'pink',
                                  out_pink_cars)

    def pred_ford_green(data_row):
        return (data_row[idx_make].lower() == 'ford'
               and data_row[idx_color].lower() == 'green')
    filter_ford_green = filter_data(pred_ford_green, out_ford_green)
    filter_older = filter_data(lambda d: d[idx_year] <= 2010, out_older)

    filters = (filter_pink_cars, filter_ford_green, filter_older)

    broadcaster = broadcast(filters)

    while True:
        data_row = yield
        broadcaster.send(data_row)


-------------------------------------------------------------------------------
# MISC NOTES
-------------------------------------------------------------------------------
# def get_dialect(file_obj):
# def get_dialect(file_obj):
#     sample = file_obj.read(2000)
#     dialect = csv.Sniffer().sniff(sample)
#     file_obj.seek(0)
#     return dialect


Vehicle_Info
Employment_Info
Ticket_Info
Personal_Info
Update_Status
